{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c07588ab",
   "metadata": {},
   "source": [
    "## Case Study 1\n",
    "#### Note: This should be completed individually.\n",
    "\n",
    "Assume you are new to the data science field, and you want to find out what real practitioners and soon-to-be data scientists are concerned about. One place where you may find such information is X (formerly known as Twitter). However, X users often use their real identities and may have reservations about sharing all their opinions publicly. Another place where such information maybe found is the datascience subreddit on Reddit.com (https://www.reddit.com/r/datascience/). Users are assumed to be anonymous and they are more likely to share their opinions without reservations. To find out common concerns among the datascience subreddit users, it might be a good idea to collect the top 100 posts in the subreddit in the year 2023. You might also collect the top 3 comments of each of those posts. In this case study, we will do exactly that. Specific details can be found in the next few cells. \n",
    "\n",
    "This data can be used for many different projects. However, we are only going to focus on the \"data gathering\" part. We will also do some cleaning.\n",
    "\n",
    "**Note**: This case study contributes 10% to your overall grade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e4b624",
   "metadata": {},
   "source": [
    "## Step 1: \n",
    "###  15 points\n",
    "\n",
    "\n",
    "**Description:** \n",
    "\n",
    "Learn about the **PRAW** package for Python and learn how you can use it to load reddit posts, comments etc. on a Jupyter Notebook. Do a Google search. You might find tutorials. It is okay to use them. You may need to use secret keys for this part. For that you will need to open a Reddit account. You can use a throwaway account for this purpose. Write your code in the cell below. Any code you write to retrieve data from Reddit can go there.\n",
    "\n",
    "Here is a link to the PRAW documentation: https://praw.readthedocs.io/en/stable/#getting-started\n",
    "\n",
    "**Grading criteria:** \n",
    "\n",
    "The code for this step must be correct. Otherwise, the next steps cannot be completed. In that case, the next steps will not be graded. If you receive a praw object from the data science subreddit, you will get full 15 points.' Other methods may be considered, but not encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf6c1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (7.7.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from praw) (2.3.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from praw) (0.58.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.28.1)\n",
      "Requirement already satisfied: six in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from websocket-client>=0.54.0->praw) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "# your code for step 1 goes here\n",
    "! pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822357fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import *\n",
    "import pandas as pd\n",
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"nie3NCVXY1oPnnBXc9mJ3Q\",\n",
    "    client_secret=\"016KwctvgJzv0NeBVCCKicseRl-q5g\",\n",
    "    username=\"DataScientist2602\",\n",
    "    password=\"Santhosh26@\",\n",
    "    user_agent=\"DS501-CS1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea70d5",
   "metadata": {},
   "source": [
    "## Step 2: \n",
    "### 10 + 20 + 10 + 15 + 5 + 5 = 65 points\n",
    "\n",
    "**Description**:\n",
    "Once you have the mechanism in place to retrieve data from Reddit, you next step is to determine which parts of the data is necessary. For this case study, collect only the top posts from the year 2023. Also consider if the score of each post was above 50 or not. If the score was below 50, it might not have been an important post. Do not consider those posts. \n",
    "\n",
    "You may also observe that sometimes posts with memes or jokes get a lot of 'upvotes,' and because of that they may  have high scores, but they may not be useful for this case study. To address this problem, you will simply get rid of any post that has fewer than 5 words in the title. \n",
    "\n",
    "You will also notice that praw returns time as an integer. It is inconvenient for us to read time like that. You may want to convert the integer time to human readable time. You do not need to mention hours, minutes, or seconds. Just year, month and date is enough.\n",
    "\n",
    "**Grading Criteria:**\n",
    "* posts are only from the year 2023: 10 points\n",
    "* the integer time format converted into year-month-day: 20 points\n",
    "* only posts with scores more than 50 were considered: 10 points\n",
    "* only post titles with more than 5 words were kept: 15 points\n",
    "* minimum 100 posts were collected: 5 points\n",
    "* three comments collected for each post: 5 points\n",
    "\n",
    "Note: All six grading criteria can be satified by writing one line or many lines of code. It does not matter. As long as your code satisfies the six criteria (in one line or many lines), you will get full points. Otherwise, you will get partial credits.\n",
    "\n",
    "Also note: In case the API does not allow you to collect 100 posts, you can collect 80 or 90 etc. In that case, please copy and paste the error message in a new cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f44da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code for step 2 goes here\n",
    "# create as many cells as necessary\n",
    "subredditname=\"datascience\" # Name of our SubReddit\n",
    "'''To get posts from the beginning of the year,\n",
    "   we import datetime package above and use datetime function to get the specified date.\n",
    "'''\n",
    "data=[]\n",
    "\n",
    "def get_human_readable_time(timestamp):\n",
    "    return datetime.utcfromtimestamp(timestamp).strftime(\"%Y-%m-%d\")\n",
    "# Get the current date\n",
    "end_date = datetime(2023,12,31).timestamp()\n",
    "start_date=datetime(2023,1,1).timestamp()\n",
    "\n",
    "# Fetch submissions from the subreddit (fetch more than you need)\n",
    "submissions = reddit.subreddit(subredditname).top(time_filter='year',limit=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4752ba89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Post Score                                         Post Title  \\\n",
      "0  2023-01-27        2636        As a hiring manager - this, this right here   \n",
      "1  2023-04-26        1979  Pretty Accurate Chart to Clear Up Job Title Am...   \n",
      "2  2023-01-20        1382  300,000+ Tech jobs have been vanished in the l...   \n",
      "3  2023-02-27        1236    Which programming language is required for a...   \n",
      "4  2023-07-17        1225                   XKCD Comic does machine learning   \n",
      "\n",
      "                                       Top Comment 1  \\\n",
      "0  He also has a PhD in mathematics so I'm sure t...   \n",
      "1  > _Yeah, well, that's just, like, your opinion...   \n",
      "2  Based on your chart it's 200k+ in the past six...   \n",
      "3  It's a shame you didn't copy the FAIRLY useful...   \n",
      "4  Yes but how do you stir the pile correctly the...   \n",
      "\n",
      "                                       Top Comment 2  \\\n",
      "0  Iâ€™m assuming he had a strong mathematical/stat...   \n",
      "1  \\nChart : Ambiguous\\nJob Title Ambiguities : e...   \n",
      "2  Someone else posted something similar but inst...   \n",
      "3  It's never matlab, why did my PhD supervisor m...   \n",
      "4                  This is so unfortunately accurate   \n",
      "\n",
      "                                       Top Comment 3  \n",
      "0  How seriously are personal projects taken? I'm...  \n",
      "1  I've done all of those things, in varying amou...  \n",
      "2     If my data viz was this bad I would deserve it  \n",
      "3  Php ðŸ¤£ðŸ¤£ðŸ¤£ has the author learned php and trying ...  \n",
      "4  Me when I learned you could just write Axâ‰ˆb fo...  \n",
      "           Date  Post Score  \\\n",
      "556  2023-08-23          52   \n",
      "557  2023-08-14          50   \n",
      "558  2023-02-23          47   \n",
      "559  2023-06-19          46   \n",
      "560  2023-02-21          50   \n",
      "\n",
      "                                            Post Title  \\\n",
      "556  new MS Data Science grad w/ 6mo data analyst i...   \n",
      "557  What harshest advice would you give to me? Any...   \n",
      "558             Build simple web-app as Data Scientist   \n",
      "559         Interesting screenshot about ML production   \n",
      "560  How impressive is a high Kaggle ranking for em...   \n",
      "\n",
      "                                         Top Comment 1  \\\n",
      "556  \\> \"not showing enough interest for the compan...   \n",
      "557  I've done a fair bit of hiring of NLP-focussed...   \n",
      "558  You should check out Dash, itâ€™s an awesome fra...   \n",
      "559            Damn... True? Then I need tissues Ig...   \n",
      "560  For whatever it's worth:\\n\\nI work in auto ins...   \n",
      "\n",
      "                                         Top Comment 2  \\\n",
      "556  What about the job market in electrical engine...   \n",
      "557  Being harsh:\\n\\n\"Collaborated on...\", \"Delved ...   \n",
      "558  Streamlit might do what you want. \\n\\nEither t...   \n",
      "559                                                      \n",
      "560  I am surprised at the responses.\\n\\nHonestly, ...   \n",
      "\n",
      "                                         Top Comment 3  \n",
      "556  Howâ€™s your project portfolio? If you want you ...  \n",
      "557  Nice resume to go further in numerical physics...  \n",
      "558  Flask or django, but I find the user managemen...  \n",
      "559                                                     \n",
      "560  No one cares about Kaggle. Can it be great lea...  \n"
     ]
    }
   ],
   "source": [
    "# Fetch submissions from the subreddit\n",
    "for submission in submissions:\n",
    "    submission_time = submission.created_utc\n",
    "    # Check if the submission is from the specified date range and score is more than 50 and title words are more than 5\n",
    "    if start_date <= submission_time <= end_date and submission.score > 50 and len(submission.title.split()) >= 5:\n",
    "        submission.comments.replace_more(limit=10)\n",
    "        top_comments = []\n",
    "\n",
    "        # skipping deleted comments and adding the next top comment\n",
    "        for comment in submission.comments:\n",
    "            if isinstance(comment, praw.models.Comment) and not comment.body == \"[deleted]\":\n",
    "                top_comments.append(comment.body)\n",
    "                \n",
    "            # Break if we have collected 3 non-deleted top comments\n",
    "            if len(top_comments) == 3:\n",
    "                break\n",
    "\n",
    "        # Ensure there are exactly 3 top comments\n",
    "        top_comments.extend([\"\"] * (3 - len(top_comments)))\n",
    "\n",
    "        data.append([\n",
    "            get_human_readable_time(submission_time),\n",
    "            submission.score,\n",
    "            submission.title,\n",
    "            *top_comments\n",
    "        ])\n",
    "\n",
    "# Create a Pandas DataFrame from the collected data\n",
    "df = pd.DataFrame(data, columns=[\"Date\", \"Post Score\", \"Post Title\", \"Top Comment 1\", \"Top Comment 2\", \"Top Comment 3\"])\n",
    "\n",
    "# Print the first few rows and the last few rows of the DataFrame\n",
    "print(df.head())\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5be6c819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             561\n",
       "Post Score       561\n",
       "Post Title       561\n",
       "Top Comment 1    561\n",
       "Top Comment 2    561\n",
       "Top Comment 3    561\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136d051",
   "metadata": {},
   "source": [
    "## Step 3: \n",
    "### 10 points\n",
    "\n",
    "Save the data on your local disk. You may have used lists or similar data structures for the intial porcessing. Convert that data structure into a Pandas dataframe. Save the dataframe as a .csv file into your local disk. \n",
    "\n",
    "Here are the column details:\n",
    "\n",
    "Column 1: Date\n",
    "\n",
    "Column 2: Post score\n",
    "\n",
    "Column 3: Post title\n",
    "\n",
    "Column 4: Top comment 1\n",
    "\n",
    "Column 5: Top comment 2\n",
    "\n",
    "Column 6: Top comment 3\n",
    "\n",
    "When you create the .csv file, it should have 101 rows (including column names) and 6 columns.\n",
    "\n",
    "**Grading criteria:**\n",
    "If your code produces a .csv file in the local disk in the same folder as the Jupyter Notebook file, you get full points. Otherwise, no point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ee47057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code for step 3 goes here\n",
    "# create as many cells as necessary\n",
    "df.to_csv(\"NityaPhaniSantosh_Oruganty_CaseStudy_1.csv\", index=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b12bd",
   "metadata": {},
   "source": [
    "## Step 4:\n",
    "### 10 points\n",
    "#### Presentation slides:\n",
    "   \n",
    "Create presentation slides for this case study. The presentation slides should provide an overview of the problem you tried to solve, methods you have used (don't put actual code in the slides), and if you have discovered new insights from the data you have collected. You may put actual post titles or comments in the slide that you found insightful and interesting. The number of slides should be around 6-7 (no hard limit). Three of you will be randomly chosen and be asked to present your work in the class. You should be prepared to present your work for 5 mins.\n",
    "\n",
    "\n",
    "**Notes on grading**: 5 points will be deducted if you are not prepared to present on the day of submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e062707",
   "metadata": {},
   "source": [
    "### What to submit:\n",
    "\n",
    "All files should be named in the following format:\n",
    "\n",
    "firstname_lastname_casestudy_1.pdf\n",
    "\n",
    "firstname_lastname_casestudy_1.ipynb\n",
    "\n",
    "firstname_lastname_casestudy_1.csv\n",
    "\n",
    "etc.\n",
    "\n",
    "\n",
    "Put the Jupyter Notebook file and the .csv file in a folder. Then convert your presentation slides to a PDF file and put it in the same folder. Zip the folder. After zipping, it should have the extension .zip. The name of the .zip file should be firstname_lastname_casestudy_1.zip . Upload the .zip file on Canvas.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
